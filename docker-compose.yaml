services:
  wordsworth:
    container_name: wordsworth
    image: python:latest
#    build:
#      context: .
#      dockerfile: infra/backend.Dockerfile
    restart: "no"
#    pull_policy: build
    volumes:
#      - ./data:/app/data
      - .:/app
    ports:
      - "5000:5000"
    working_dir: /app
    command: "/bin/sh -c 'pip install -U pip; pip install -r requirements.txt; python -u -m backend'"
    environment:
      - APP__LOG_LEVEL=INFO
      - APP__ARCHIVE_FOLDER=archive
      - APP__DATA_FOLDER=data
      - APP__PROJECT_SETTINGS=project_settings.json
      - APP__INPUT_FILENAME=wordlist.json
      - APP__DATA_FILENAME=puzzledata.json
      - APP__OUTPUT_FILENAME=manuscript.pdf
      - APP__FRONTEND_HOST_FOR_CORS=http://localhost:5001
      - VITE_API_BASE_URL=http://localhost:5000

        # Not currently used, but stand by
      - AI__MODEL=gemma3:12b
      - AI__HOST=http://localhost:11434/
  dorothy:
    container_name: dorothy
    image: node:lts-alpine
    restart: "no"
    volumes:
      - .:/app
    ports:
      - "5001:5001"
    working_dir: /app/frontend
    environment:
      - VITE_API_BASE_URL=http://localhost:5000
    command: "/bin/sh -c 'npm install; npm run build; npm run serve'"
#  glados:
#    container_name: glados
#    image: ollama/ollama
#    restart: "no"
#    ports:
#      - "11434:11434"
#    volumes:
#      - ./ai-data/backend:/root/.ollama/
##    deploy:
##      resources:
##        reservations:
##          devices:
##            - driver: nvidia
##              count: all
##              capabilities: [ gpu ]
#  holly:
#    container_name: holly
#    image: ghcr.io/open-webui/open-webui:main
#    pull_policy: always
#    volumes:
#      - ./ai-data/open-webui:/app/backend/data
#    depends_on:
#      - glados
#    ports:
#      - 3000:8080
#    environment:
#      - 'OLLAMA_BASE_URL=http://glados:11434'
#    extra_hosts:
#      - host.docker.internal:host-gateway
#    restart: unless-stopped